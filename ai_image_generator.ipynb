{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9Fmq5ec9O60",
        "outputId": "c578006e-e9cd-4b05-fdcb-8e56bcb1109c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import torch\n",
        "import uuid\n",
        "import os\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from typing import List\n",
        "\n",
        "# ----------------- Config -----------------\n",
        "OUTPUT_DIR = \"generated\"\n",
        "MODEL_ID = \"stabilityai/sd-turbo\"  # fast CPU-friendly model\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ----------------- Helper: load model -----------------\n",
        "@st.cache_resource\n",
        "def load_model(model_id: str = MODEL_ID):\n",
        "    \"\"\"\n",
        "    Loads the Stable Diffusion pipeline. Uses float16 on CUDA and float32 on CPU.\n",
        "    \"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
        "\n",
        "    try:\n",
        "        pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=dtype)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\n",
        "            f\"Failed to load model '{model_id}'. Make sure it's available and you have internet access.\\nOriginal error: {e}\"\n",
        "        )\n",
        "\n",
        "    pipe = pipe.to(device)\n",
        "    # Perf hints (if available)\n",
        "    try:\n",
        "        pipe.enable_attention_slicing()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return pipe, device\n",
        "\n",
        "pipe, device = load_model()\n",
        "\n",
        "# ----------------- Image generation -----------------\n",
        "def generate_images(pipe: StableDiffusionPipeline, prompt: str, style: str,\n",
        "                    negative_prompt: str, num_images: int) -> List[str]:\n",
        "    \"\"\"\n",
        "    Generate images with minimal steps for CPU-friendly fast output.\n",
        "    Returns list of filepaths.\n",
        "    \"\"\"\n",
        "    style = (style or \"none\").lower().strip()\n",
        "    engineered_prompt = prompt.strip()\n",
        "\n",
        "    # style modifiers (simple presets)\n",
        "    if style == \"photorealistic\":\n",
        "        engineered_prompt += \", ultra realistic, photo, 8k, sharp details\"\n",
        "    elif style == \"cartoon\":\n",
        "        engineered_prompt += \", cartoon, clean lines, vibrant colors\"\n",
        "    elif style == \"artistic\":\n",
        "        engineered_prompt += \", oil painting, textured brush strokes\"\n",
        "\n",
        "    files = []\n",
        "    # Use a generator only if device supports it\n",
        "    generator = None\n",
        "    if torch.cuda.is_available():\n",
        "        generator = torch.Generator(device=\"cuda\").manual_seed(int(torch.randint(0, 2**31 - 1, (1,)).item()))\n",
        "    else:\n",
        "        generator = torch.Generator(device=\"cpu\").manual_seed(int(torch.randint(0, 2**31 - 1, (1,)).item()))\n",
        "\n",
        "    # SD-Turbo works well with very low steps and guidance on CPU\n",
        "    for _ in range(num_images):\n",
        "        out = pipe(\n",
        "            engineered_prompt,\n",
        "            negative_prompt=negative_prompt or None,\n",
        "            guidance_scale=1.0,        # low guidance for speed + diversity\n",
        "            num_inference_steps=1,    # 1 step for Turbo â€” very fast on CPU\n",
        "            generator=generator\n",
        "        )\n",
        "        img = out.images[0]\n",
        "        filename = f\"{uuid.uuid4()}.png\"\n",
        "        filepath = os.path.join(OUTPUT_DIR, filename)\n",
        "        img.save(filepath)\n",
        "        files.append(filepath)\n",
        "    return files\n",
        "\n",
        "# ----------------- Streamlit UI -----------------\n",
        "st.set_page_config(page_title=\"Fast SD-Turbo Image Generator\", layout=\"centered\")\n",
        "st.title(\"ðŸŽ¨ Fast Stable Diffusion â€” SD Turbo (CPU friendly)\")\n",
        "st.write(f\"Using device: **{device.upper()}**\")\n",
        "\n",
        "with st.form(\"generate_form\"):\n",
        "    prompt = st.text_area(\"Enter prompt:\", height=120, placeholder=\"A beautiful portrait of ...\")\n",
        "    style = st.selectbox(\"Select style:\", [\"None\", \"Photorealistic\", \"Cartoon\", \"Artistic\"])\n",
        "    negative_prompt = st.text_input(\"Negative prompt (optional):\")\n",
        "    num_images = st.slider(\"Number of images\", 1, 4, 1)\n",
        "    submit = st.form_submit_button(\"Generate\")\n",
        "\n",
        "if submit:\n",
        "    if not prompt or prompt.strip() == \"\":\n",
        "        st.error(\"Please enter a prompt.\")\n",
        "    else:\n",
        "        try:\n",
        "            with st.spinner(\"Generating images (fast)...\"):\n",
        "                generated_files = generate_images(pipe, prompt, style, negative_prompt, num_images)\n",
        "\n",
        "            st.success(\"Images generated!\")\n",
        "            cols = st.columns(min(4, len(generated_files)))\n",
        "            for i, fp in enumerate(generated_files):\n",
        "                with open(fp, \"rb\") as f:\n",
        "                    img_bytes = f.read()\n",
        "                cols[i % len(cols)].image(img_bytes, use_column_width=True, caption=os.path.basename(fp))\n",
        "                cols[i % len(cols)].download_button(\"Download\", data=img_bytes, file_name=os.path.basename(fp), mime=\"image/png\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Image generation failed: {e}\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.info(\"Model: **sd-turbo** (fast, CPU-friendly). If you have GPU later, this app will use it automatically.\")\n",
        "st.caption(\"If you want higher-fidelity images and have GPU access, ask me to switch back to a GPU-optimized model and settings.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit diffusers transformers accelerate safetensors \\\n",
        "  && pip install torch --index-url https://download.pytorch.org/whl/cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYEmVss9-BXd",
        "outputId": "98072b12-1d1c-4b5d-bc6b-5ce507c589b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (0.35.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.7.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from diffusers) (0.36.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers) (2025.11.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers) (3.23.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.51.0\n",
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra9-wtt5-PZ3",
        "outputId": "7f923841-f925-4cb4-b3ab-b98b0fb0b59b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"360vuoLKLRMXDdC2F26dggbKIQa_4azM5P1v6wRrZ2uYEXPk\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVnPU2Rn-nC9",
        "outputId": "582974f6-b36f-493a-824d-5e1c4dcd8252"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(6006, proto=\"http\")\n",
        "print(public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkL7JH6_-pk8",
        "outputId": "cc4c494d-d041-45bc-de43-5f130574f9d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://unexpanded-threatless-micki.ngrok-free.dev\" -> \"http://localhost:6006\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port=6006 --server.headless true &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogI2x8fD-tLo",
        "outputId": "16629b81-337a-477f-e898-e81716cefabb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:6006\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:6006\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.223.231.234:6006\u001b[0m\n",
            "\u001b[0m\n",
            "2025-11-27 11:03:20.043776: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764241400.059850    2018 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764241400.064513    2018 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764241400.076743    2018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764241400.076786    2018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764241400.076790    2018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764241400.076793    2018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "model_index.json: 100% 616/616 [00:00<00:00, 4.10MB/s]\n",
            "Fetching 12 files:   0% 0/12 [00:00<?, ?it/s]\n",
            "scheduler_config.json: 100% 553/553 [00:00<00:00, 4.55MB/s]\n",
            "Fetching 12 files:  17% 2/12 [00:00<00:00, 11.23it/s]\n",
            "config.json: 100% 618/618 [00:00<00:00, 3.92MB/s]\n",
            "\n",
            "tokenizer_config.json: 100% 855/855 [00:00<00:00, 6.78MB/s]\n",
            "\n",
            "merges.txt: 0.00B [00:00, ?B/s]\u001b[A\n",
            "\n",
            "special_tokens_map.json: 100% 574/574 [00:00<00:00, 5.06MB/s]\n",
            "\n",
            "\n",
            "config.json: 1.87kB [00:00, 8.36MB/s]\n",
            "\n",
            "\n",
            "text_encoder/model.safetensors:   0% 0.00/1.36G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:   0% 0.00/3.46G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "merges.txt: 525kB [00:00, 7.44MB/s]\n",
            "\n",
            "config.json: 100% 655/655 [00:00<00:00, 5.36MB/s]\n",
            "\n",
            "vocab.json: 1.06MB [00:00, 11.9MB/s]\n",
            "\n",
            "\n",
            "text_encoder/model.safetensors:   0% 178k/1.36G [00:01<2:23:38, 158kB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:   0% 4.27M/1.36G [00:01<05:22, 4.21MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:   1% 12.3M/1.36G [00:01<01:47, 12.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:   0% 8.13k/3.46G [00:01<176:04:08, 5.46kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:   1% 51.5M/3.46G [00:01<01:17, 44.3MB/s]    \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:   2% 20.6M/1.36G [00:01<01:09, 19.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:   2% 24.7M/1.36G [00:01<01:14, 18.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:   3% 105M/3.46G [00:02<00:45, 74.6MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:   3% 34.8M/1.36G [00:02<00:54, 24.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:   4% 54.9M/1.36G [00:02<00:29, 43.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:   5% 183M/3.46G [00:02<00:30, 106MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:   5% 71.4M/1.36G [00:02<00:21, 60.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:   7% 252M/3.46G [00:02<00:25, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  10% 359M/3.46G [00:03<00:15, 201MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:   6% 79.7M/1.36G [00:03<00:41, 30.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:   7% 91.7M/1.36G [00:03<00:40, 31.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:   7% 99.1M/1.36G [00:03<00:40, 30.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:   8% 107M/1.36G [00:04<00:39, 32.0MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  13% 439M/3.46G [00:04<00:24, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  17% 589M/3.46G [00:04<00:13, 215MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:   9% 120M/1.36G [00:04<00:39, 31.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  10% 136M/1.36G [00:04<00:26, 45.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  11% 144M/1.36G [00:04<00:24, 49.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  12% 163M/1.36G [00:04<00:17, 70.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  15% 201M/1.36G [00:05<00:09, 117MB/s] \u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  16% 222M/1.36G [00:05<00:12, 94.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  18% 242M/1.36G [00:05<00:10, 105MB/s] \u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  19% 263M/1.36G [00:05<00:09, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  21% 284M/1.36G [00:06<00:14, 72.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  22% 305M/1.36G [00:06<00:14, 71.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  24% 321M/1.36G [00:06<00:17, 60.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  25% 339M/1.36G [00:07<00:16, 63.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  27% 369M/1.36G [00:07<00:12, 81.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  29% 389M/1.36G [00:07<00:10, 96.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  31% 418M/1.36G [00:07<00:07, 126MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  20% 684M/3.46G [00:08<00:43, 64.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  22% 754M/3.46G [00:08<00:38, 70.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  24% 821M/3.46G [00:11<00:52, 50.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  28% 956M/3.46G [00:11<00:30, 81.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  31% 1.09G/3.46G [00:11<00:20, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  35% 1.22G/3.46G [00:12<00:13, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  37% 1.30G/3.46G [00:12<00:14, 151MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  32% 437M/1.36G [00:12<01:10, 13.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  39% 1.36G/3.46G [00:12<00:11, 182MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  41% 1.43G/3.46G [00:12<00:09, 212MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  43% 1.50G/3.46G [00:13<00:08, 224MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  45% 1.57G/3.46G [00:15<00:22, 82.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  33% 449M/1.36G [00:15<01:35, 9.52MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  49% 1.71G/3.46G [00:15<00:13, 128MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  51% 1.78G/3.46G [00:16<00:11, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  34% 466M/1.36G [00:16<01:15, 11.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  35% 475M/1.36G [00:16<01:05, 13.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  35% 482M/1.36G [00:16<00:56, 15.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  53% 1.85G/3.46G [00:16<00:10, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  37% 503M/1.36G [00:16<00:35, 24.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  55% 1.91G/3.46G [00:16<00:09, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  38% 511M/1.36G [00:16<00:32, 26.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  57% 1.98G/3.46G [00:16<00:07, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  39% 528M/1.36G [00:16<00:23, 35.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  40% 541M/1.36G [00:17<00:20, 39.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  59% 2.05G/3.46G [00:17<00:07, 202MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  40% 550M/1.36G [00:17<00:21, 38.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  42% 567M/1.36G [00:19<00:50, 15.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Fetching 12 files:  17% 2/12 [00:19<00:00, 11.23it/s]\n",
            "\n",
            "text_encoder/model.safetensors:  43% 587M/1.36G [00:19<00:32, 23.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  45% 608M/1.36G [00:19<00:23, 32.2MB/s]\u001b[A\u001b[A\n",
            "vae/diffusion_pytorch_model.safetensors:  20% 66.4M/335M [00:20<01:21, 3.30MB/s]\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  63% 2.18G/3.46G [00:25<00:46, 27.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  46% 620M/1.36G [00:25<01:40, 7.40MB/s]\u001b[A\u001b[A\n",
            "vae/diffusion_pytorch_model.safetensors:  40% 133M/335M [00:25<00:34, 5.77MB/s] \u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  65% 2.25G/3.46G [00:25<00:32, 37.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  46% 628M/1.36G [00:27<01:43, 7.10MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  67% 2.32G/3.46G [00:27<00:28, 40.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  46% 632M/1.36G [00:27<01:43, 7.06MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  51% 693M/1.36G [00:29<00:43, 15.3MB/s]\u001b[A\u001b[A\n",
            "vae/diffusion_pytorch_model.safetensors:  60% 200M/335M [00:29<00:16, 8.22MB/s]\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  53% 720M/1.36G [00:29<00:29, 21.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  69% 2.39G/3.46G [00:30<00:30, 34.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  71% 2.46G/3.46G [00:30<00:21, 46.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  54% 741M/1.36G [00:30<00:25, 24.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  56% 767M/1.36G [00:30<00:17, 33.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  58% 788M/1.36G [00:30<00:13, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  59% 801M/1.36G [00:35<00:53, 10.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  73% 2.53G/3.46G [00:36<00:37, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  60% 819M/1.36G [00:36<00:39, 13.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  62% 842M/1.36G [00:36<00:26, 19.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  63% 854M/1.36G [00:36<00:21, 23.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  75% 2.59G/3.46G [00:36<00:26, 33.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  65% 888M/1.36G [00:36<00:12, 38.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  67% 917M/1.36G [00:36<00:08, 55.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  69% 937M/1.36G [00:36<00:06, 63.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  77% 2.66G/3.46G [00:37<00:19, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  79% 2.73G/3.46G [00:37<00:13, 55.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  70% 953M/1.36G [00:37<00:07, 51.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  81% 2.79G/3.46G [00:37<00:09, 70.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  83% 2.86G/3.46G [00:37<00:06, 91.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  71% 967M/1.36G [00:38<00:09, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  73% 992M/1.36G [00:38<00:06, 56.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  85% 2.93G/3.46G [00:38<00:04, 112MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  74% 1.01G/1.36G [00:38<00:05, 65.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  77% 1.05G/1.36G [00:38<00:03, 95.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  78% 1.07G/1.36G [00:38<00:02, 98.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  83% 1.13G/1.36G [00:39<00:01, 116MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  86% 3.00G/3.46G [00:39<00:04, 94.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  85% 1.16G/1.36G [00:39<00:01, 117MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  88% 3.06G/3.46G [00:39<00:03, 106MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  90% 3.13G/3.46G [00:39<00:02, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  87% 1.18G/1.36G [00:40<00:02, 72.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  92% 3.20G/3.46G [00:40<00:01, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  88% 1.19G/1.36G [00:40<00:02, 67.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  89% 1.21G/1.36G [00:40<00:02, 74.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  94% 3.26G/3.46G [00:40<00:01, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  96% 3.33G/3.46G [00:40<00:00, 177MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  90% 1.23G/1.36G [00:41<00:02, 54.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors:  98% 3.40G/3.46G [00:41<00:00, 170MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder/model.safetensors:  96% 1.30G/1.36G [00:41<00:00, 87.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors: 100% 3.46G/3.46G [00:41<00:00, 83.0MB/s]\n",
            "\n",
            "vae/diffusion_pytorch_model.safetensors:  80% 268M/335M [00:41<00:09, 6.89MB/s]\u001b[A\n",
            "vae/diffusion_pytorch_model.safetensors: 100% 335M/335M [00:42<00:00, 7.93MB/s]\n",
            "\n",
            "\n",
            "text_encoder/model.safetensors: 100% 1.36G/1.36G [00:42<00:00, 31.9MB/s]\n",
            "Fetching 12 files: 100% 12/12 [00:42<00:00,  3.57s/it]\n",
            "Loading pipeline components...:  60% 3/5 [00:01<00:00,  2.35it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading pipeline components...: 100% 5/5 [00:01<00:00,  2.62it/s]\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "100% 1/1 [00:33<00:00, 33.89s/it]\n",
            "2025-11-27 11:05:59.358 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nwYe_YFQ-xFa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}